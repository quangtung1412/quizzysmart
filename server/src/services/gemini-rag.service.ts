/**
 * Gemini RAG Service
 * 
 * Handles PDF extraction, embedding, and answer generation using Google Gemini AI
 */

import { GoogleGenAI, createPartFromUri } from '@google/genai';
import { jsonrepair } from 'jsonrepair';
import type {
  DocumentContent,
  DocumentMetadata,
  GeminiExtractionResponse,
  GeminiEmbeddingResponse,
  RAGQuery,
  RAGResponse,
  RetrievedChunk,
} from '../types/rag.types.js';
import { geminiModelRotation } from '../gemini-model-rotation.js';
import { qdrantService } from './qdrant.service.js';
import { modelSettingsService } from './model-settings.service.js';
import { geminiTrackerService } from './gemini-tracker.service.js';

class GeminiRAGService {
  private ai: GoogleGenAI;
  private maxRetries = 3;
  private retryDelay = 2000; // Start with 2 seconds

  constructor(apiKey?: string) {
    // Allow custom API key, default to GEMINI_API_KEY
    const key = apiKey || process.env.GEMINI_API_KEY;
    if (!key) {
      throw new Error('GEMINI_API_KEY not found in environment');
    }

    this.ai = new GoogleGenAI({ apiKey: key });
  }

  /**
   * Get appropriate model for answering (respects model rotation settings)
   */
  private async getAnswerModel(): Promise<{ name: string; priority: number }> {
    // Try to get system settings to check if rotation is enabled
    try {
      const { PrismaClient } = await import('@prisma/client');
      const prisma = new PrismaClient();
      const systemSettings = await (prisma as any).systemSettings.findFirst();
      await prisma.$disconnect();

      if (systemSettings && !systemSettings.modelRotationEnabled) {
        // Model rotation is disabled - use default model from model settings
        const defaultModel = await modelSettingsService.getDefaultModel();
        console.log(`[Gemini] Model rotation DISABLED - Using default model: ${defaultModel}`);
        return { name: defaultModel, priority: 0 };
      }
    } catch (error) {
      console.warn('[Gemini] Could not check system settings, using rotation:', error);
    }

    // Model rotation is enabled - use rotation
    const modelInfo = await geminiModelRotation.getNextAvailableModel();
    if (!modelInfo) {
      throw new Error('No available Gemini models');
    }
    console.log(`[Gemini] Model rotation ENABLED - Using: ${modelInfo.name}`);
    return modelInfo;
  }

  /**
   * Sleep utility for retry delays
   */
  private async sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Check if error is retryable (503, 429, network errors)
   */
  private isRetryableError(error: any): boolean {
    const errorStr = error.toString().toLowerCase();
    return (
      errorStr.includes('503') ||
      errorStr.includes('overloaded') ||
      errorStr.includes('429') ||
      errorStr.includes('quota') ||
      errorStr.includes('rate limit') ||
      errorStr.includes('unavailable')
    );
  }

  /**
   * Upload PDF to Gemini File API
   */
  async uploadPDF(filePath: string, displayName: string): Promise<string> {
    try {
      console.log(`[Gemini] Uploading PDF to File API: ${displayName}`);

      // Read file as buffer
      const fs = await import('fs');
      const fileBuffer = await fs.promises.readFile(filePath);
      const fileBlob = new Blob([new Uint8Array(fileBuffer)], { type: 'application/pdf' });

      const file = await this.ai.files.upload({
        file: fileBlob,
        config: {
          displayName: displayName,
        },
      });

      console.log(`[Gemini] PDF uploaded successfully. URI: ${file.uri}`);

      if (!file.uri) {
        throw new Error('File URI is undefined');
      }

      return file.uri;
    } catch (error) {
      console.error('[Gemini] PDF upload failed:', error);
      throw new Error(`Failed to upload PDF: ${error}`);
    }
  }

  /**
   * Extract structured content from PDF using Gemini
   */
  async extractDocumentContent(fileUri: string): Promise<GeminiExtractionResponse> {
    try {
      console.log(`[Gemini] Extracting content from: ${fileUri}`);

      // Wait for file to be processed (if it's a fresh upload)
      const fileName = fileUri.split('/').pop()!;
      let fileInfo = await this.ai.files.get({ name: fileName });
      console.log(`[Gemini] File state: ${fileInfo.state}`);

      while (fileInfo.state === 'PROCESSING') {
        console.log('[Gemini] File is still processing, waiting 5 seconds...');
        await new Promise((resolve) => setTimeout(resolve, 5000));
        fileInfo = await this.ai.files.get({ name: fileName });
      }

      if (fileInfo.state === 'FAILED') {
        throw new Error('File processing failed');
      }

      console.log(`[Gemini] File ready, state: ${fileInfo.state}`);

      const prompt = `
Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch vÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  trÃ­ch xuáº¥t CHÃNH XÃC vÃ  Äáº¦Y Äá»¦ toÃ n bá»™ ná»™i dung tá»« vÄƒn báº£n PDF.

YÃŠU Cáº¦U QUAN TRá»ŒNG:
1. TrÃ­ch xuáº¥t TOÃ€N Bá»˜ vÄƒn báº£n, khÃ´ng Ä‘Æ°á»£c bá» sÃ³t báº¥t ká»³ pháº§n nÃ o
2. Giá»¯ nguyÃªn cáº¥u trÃºc phÃ¢n cáº¥p: ChÆ°Æ¡ng â†’ Äiá»u â†’ Khoáº£n â†’ Äiá»ƒm
3. Tráº£ vá» JSON vá»›i cáº¥u trÃºc chuáº©n nhÆ° bÃªn dÆ°á»›i
4. Ná»™i dung pháº£i Ä‘Æ°á»£c format theo Markdown Ä‘á»ƒ dá»… Ä‘á»c
5. CÃ¡c sá»‘ Ä‘iá»u, khoáº£n pháº£i chÃ­nh xÃ¡c
6. JSON PHáº¢I HOÃ€N TOÃ€N Há»¢P Lá»†:
   - KHÃ”NG cÃ³ trailing commas (dáº¥u pháº©y thá»«a trÆ°á»›c }, ])
   - Táº¥t cáº£ strings pháº£i Ä‘Æ°á»£c escape Ä‘Ãºng (\n cho newline, \" cho quotes)
   - KHÃ”NG cÃ³ control characters
   - Má»—i pháº§n tá»­ trong array pháº£i cÃ³ dáº¥u pháº©y ngÄƒn cÃ¡ch (trá»« pháº§n tá»­ cuá»‘i)
   - Táº¥t cáº£ {} vÃ  [] pháº£i Ä‘Ã³ng má»Ÿ Ä‘Ãºng cáº·p

Cáº¥u trÃºc JSON yÃªu cáº§u:
{
  "overview": {
    "documentNumber": "Sá»‘ vÄƒn báº£n (vÃ­ dá»¥: 01/2024/TT-NHNN)",
    "documentName": "TÃªn Ä‘áº§y Ä‘á»§ vÄƒn báº£n",
    "documentType": "Loáº¡i vÄƒn báº£n (ThÃ´ng tÆ°/Nghá»‹ Ä‘á»‹nh/Quyáº¿t Ä‘á»‹nh/...)",
    "issuingAgency": "CÆ¡ quan ban hÃ nh",
    "signer": {
      "name": "TÃªn ngÆ°á»i kÃ½",
      "title": "Chá»©c danh"
    },
    "signedDate": "NgÃ y kÃ½ (format: YYYY-MM-DD)"
  },
  "basis": [
    {
      "type": "Loáº¡i cÄƒn cá»© (Luáº­t/Nghá»‹ Ä‘á»‹nh/...)",
      "number": "Sá»‘ vÄƒn báº£n cÄƒn cá»©",
      "name": "TÃªn vÄƒn báº£n cÄƒn cá»©",
      "date": "NgÃ y ban hÃ nh (náº¿u cÃ³)"
    }
  ],
  "chapters": [
    {
      "number": "Sá»‘ chÆ°Æ¡ng (I, II, III hoáº·c 1, 2, 3)",
      "title": "TÃªn chÆ°Æ¡ng",
      "articles": [
        {
          "number": "Sá»‘ Ä‘iá»u",
          "title": "TÃªn Ä‘iá»u (náº¿u cÃ³)",
          "content": "Ná»™i dung Ä‘iá»u (náº¿u khÃ´ng cÃ³ khoáº£n)",
          "sections": [
            {
              "number": "Sá»‘ khoáº£n (1, 2, 3 hoáº·c a, b, c)",
              "content": "Ná»™i dung khoáº£n (Markdown format)",
              "subsections": [
                "Äiá»ƒm a: ná»™i dung",
                "Äiá»ƒm b: ná»™i dung"
              ]
            }
          ]
        }
      ]
    }
  ],
  "articles": [
    // DÃ¹ng khi vÄƒn báº£n KHÃ”NG cÃ³ chÆ°Æ¡ng, chá»‰ cÃ³ Ä‘iá»u
    {
      "number": "Sá»‘ Ä‘iá»u",
      "title": "TÃªn Ä‘iá»u",
      "sections": [...]
    }
  ],
  "appendices": [
    {
      "number": "Sá»‘ phá»¥ lá»¥c",
      "title": "TÃªn phá»¥ lá»¥c",
      "content": "Ná»™i dung phá»¥ lá»¥c (Markdown)"
    }
  ]
}

QUAN TRá»ŒNG:
- Náº¿u vÄƒn báº£n cÃ³ chÆ°Æ¡ng, sá»­ dá»¥ng trÆ°á»ng "chapters"
- Náº¿u vÄƒn báº£n KHÃ”NG cÃ³ chÆ°Æ¡ng, sá»­ dá»¥ng trÆ°á»ng "articles" trá»±c tiáº¿p
- Má»—i Ä‘iá»u pháº£i cÃ³ Ä‘áº§y Ä‘á»§ cÃ¡c khoáº£n (náº¿u cÃ³)
- Format ná»™i dung theo Markdown: dÃ¹ng **bold**, *italic*, bullet points khi cáº§n
- Giá»¯ nguyÃªn sá»‘ thá»© tá»± Ä‘iá»u, khoáº£n, Ä‘iá»ƒm
- QUAN TRá»ŒNG NHáº¤T: Äáº£m báº£o JSON output hoÃ n toÃ n há»£p lá»‡, khÃ´ng cÃ³ trailing commas, escape Ä‘Ãºng cÃ¡c special characters trong strings

HÃ£y phÃ¢n tÃ­ch vÄƒn báº£n PDF vÃ  tráº£ vá» ONLY JSON theo Ä‘Ãºng cáº¥u trÃºc trÃªn, khÃ´ng thÃªm text giáº£i thÃ­ch.
`;

      // Create content with file URI part
      const contents: any[] = [prompt];

      if (fileInfo.uri && fileInfo.mimeType) {
        contents.push(createPartFromUri(fileInfo.uri, fileInfo.mimeType));
      }

      // Use gemini-2.5-flash for extraction with retry logic
      let lastError: any;
      for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
        try {
          console.log(`[Gemini] Extraction attempt ${attempt}/${this.maxRetries}`);

          const trackingId = await geminiTrackerService.startTracking({
            endpoint: 'generateContent',
            modelName: 'gemini-2.5-flash',
            requestType: 'document_extraction',
            metadata: { fileUri },
          });

          const response = await this.ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents,
          });

          const text = response.text || '';
          const usageMetadata: any = (response as any).usageMetadata || {};
          const inputTokens = usageMetadata.promptTokenCount || 0;
          const outputTokens = usageMetadata.candidatesTokenCount || 0;

          await geminiTrackerService.endTracking(trackingId, {
            inputTokens,
            outputTokens,
            status: 'success',
          });

          console.log(`[Gemini] Extraction completed successfully`);

          // Parse JSON response
          const jsonMatch = text.match(/\{[\s\S]*\}/);
          if (!jsonMatch) {
            throw new Error('Failed to extract JSON from Gemini response');
          }

          let documentContent: DocumentContent;
          try {
            // Try to parse JSON directly
            documentContent = JSON.parse(jsonMatch[0]);
          } catch (parseError: any) {
            console.warn(`[Gemini] Initial JSON parse failed: ${parseError.message}`);
            console.log(`[Gemini] Attempting to clean and fix JSON...`);

            // Advanced JSON cleaning and fixing
            let cleanedJson = jsonMatch[0];

            // Step 1: Remove trailing commas (most common issue)
            cleanedJson = cleanedJson.replace(/,(\s*[}\]])/g, '$1');

            // Step 2: Fix line breaks in strings (replace actual newlines with \n)
            cleanedJson = cleanedJson.replace(/"([^"]*)"(\s*:\s*"[^"]*\n[^"]*")/g, (match, key, value) => {
              return `"${key}"${value.replace(/\n/g, '\\n')}`;
            });

            // Step 3: Remove control characters except newline, tab, carriage return
            cleanedJson = cleanedJson.replace(/[\u0000-\u0008\u000B-\u000C\u000E-\u001F\u007F-\u009F]/g, '');

            // Step 4: Fix unescaped quotes within strings (complex regex)
            // This tries to find quotes that are not properly escaped
            try {
              const lines = cleanedJson.split('\n');
              const fixedLines = lines.map(line => {
                // If line contains a string value, ensure quotes inside are escaped
                if (line.includes('": "') || line.includes('":"')) {
                  // Match pattern: "key": "value with potential unescaped quotes"
                  return line.replace(/:\s*"([^"]*)"([^",\]}]*)"([^"]*)"(\s*[,\]}])/g, (match, p1, p2, p3, p4) => {
                    // If middle part doesn't start with comma/bracket, it's likely an unescaped quote
                    if (p2.trim() && !p2.trim().startsWith(',') && !p2.trim().startsWith('}') && !p2.trim().startsWith(']')) {
                      return `: "${p1}\\"${p2}\\"${p3}"${p4}`;
                    }
                    return match;
                  });
                }
                return line;
              });
              cleanedJson = fixedLines.join('\n');
            } catch (e) {
              console.warn('[Gemini] Could not apply advanced quote fixing');
            }

            try {
              documentContent = JSON.parse(cleanedJson);
              console.log(`[Gemini] JSON successfully cleaned and parsed`);
            } catch (secondError: any) {
              console.error(`[Gemini] Failed to parse JSON after manual cleaning: ${secondError.message}`);

              // Last resort: Use jsonrepair library
              try {
                console.log('[Gemini] Attempting to repair JSON using jsonrepair library...');
                const repairedJson = jsonrepair(cleanedJson);
                documentContent = JSON.parse(repairedJson);
                console.log('[Gemini] âœ… JSON successfully repaired and parsed using jsonrepair!');
              } catch (repairError: any) {
                console.error(`[Gemini] âŒ jsonrepair also failed: ${repairError.message}`);

                // Extract position from error message for debugging
                const posMatch = secondError.message.match(/position (\d+)/);
                if (posMatch) {
                  const errorPos = parseInt(posMatch[1]);
                  const start = Math.max(0, errorPos - 200);
                  const end = Math.min(cleanedJson.length, errorPos + 200);
                  console.error(`[Gemini] JSON excerpt near error position ${errorPos}:`);
                  console.error(cleanedJson.substring(start, end));
                  console.error(' '.repeat(Math.min(200, errorPos - start)) + '^--- ERROR HERE');
                }

                throw new Error(`Failed to parse JSON from Gemini response: ${secondError.message}`);
              }
            }
          }

          return {
            content: documentContent,
            rawText: text,
          };
        } catch (error) {
          lastError = error;

          if (this.isRetryableError(error)) {
            if (attempt < this.maxRetries) {
              const delay = this.retryDelay * Math.pow(2, attempt - 1); // Exponential backoff
              console.warn(`[Gemini] Retryable error (attempt ${attempt}/${this.maxRetries}): ${error}`);
              console.log(`[Gemini] Waiting ${delay}ms before retry...`);
              await this.sleep(delay);
              continue;
            } else {
              console.error(`[Gemini] Max retries reached. Last error: ${error}`);
            }
          } else {
            // Non-retryable error, fail immediately
            console.error(`[Gemini] Non-retryable error: ${error}`);
            break;
          }
        }
      }

      // If we get here, all retries failed
      throw lastError;
    } catch (error) {
      console.error('[Gemini] Content extraction failed:', error);
      throw new Error(`Failed to extract document content: ${error}`);
    }
  }

  /**
   * Generate embedding for text with retry logic
   */
  async generateEmbedding(text: string, sessionId?: string, userId?: string): Promise<number[]> {
    let lastError: any;

    // Get embedding model from settings
    const embeddingModel = await modelSettingsService.getEmbeddingModel();

    for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
      try {
        const trackingId = await geminiTrackerService.startTracking({
          endpoint: 'embedContent',
          modelName: embeddingModel,
          requestType: 'embedding',
          userId,
          sessionId,
          metadata: { textLength: text.length },
        });

        const result = await this.ai.models.embedContent({
          model: embeddingModel,
          contents: text,
          config: {
            outputDimensionality: 768  // Force 768 dimensions for compatibility
          }
        });

        if (!result.embeddings || result.embeddings.length === 0 || !result.embeddings[0].values) {
          throw new Error('Invalid embedding response');
        }

        // Estimate tokens for embedding (rough estimate: 1 token â‰ˆ 4 characters)
        const estimatedTokens = Math.ceil(text.length / 4);
        await geminiTrackerService.endTracking(trackingId, {
          inputTokens: estimatedTokens,
          outputTokens: 0,
          status: 'success',
        });

        return result.embeddings[0].values;
      } catch (error) {
        lastError = error;

        if (this.isRetryableError(error) && attempt < this.maxRetries) {
          const delay = this.retryDelay * Math.pow(2, attempt - 1);
          console.warn(`[Gemini] Embedding retry ${attempt}/${this.maxRetries}: ${error}`);
          console.log(`[Gemini] Waiting ${delay}ms before retry...`);
          await this.sleep(delay);
          continue;
        }
      }
    }

    console.error('[Gemini] Embedding generation failed:', lastError);
    throw new Error(`Failed to generate embedding: ${lastError}`);
  }

  /**
   * Generate embeddings for multiple texts (batch)
   * Optimized to send multiple texts in a single API call to reduce costs
   */
  async generateEmbeddings(texts: string[], sessionId?: string, userId?: string): Promise<number[][]> {
    try {
      const startTime = Date.now();
      console.log(`[Gemini] ğŸš€ Generating embeddings for ${texts.length} texts using batch mode`);

      if (texts.length === 0) {
        return [];
      }

      // Get embedding model from settings
      const embeddingModel = await modelSettingsService.getEmbeddingModel();

      const allEmbeddings: number[][] = [];

      // Process in batches to avoid hitting API limits
      // Gemini API supports multiple contents in one request
      const batchSize = 100; // Increased from 10 since we're now using single API call per batch
      const totalBatches = Math.ceil(texts.length / batchSize);

      console.log(`[Gemini] ğŸ’° Cost Optimization: Using ${totalBatches} API call(s) instead of ${texts.length} calls (${Math.round((1 - totalBatches / texts.length) * 100)}% reduction)`);

      for (let i = 0; i < texts.length; i += batchSize) {
        const batch = texts.slice(i, i + batchSize);
        const batchNum = Math.floor(i / batchSize) + 1;
        console.log(`[Gemini] Processing batch ${batchNum}/${totalBatches} (${batch.length} texts)`);

        let lastError: any;
        let batchEmbeddings: number[][] | null = null;

        // Retry logic for the entire batch
        for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
          try {
            const trackingId = await geminiTrackerService.startTracking({
              endpoint: 'embedContent',
              modelName: embeddingModel,
              requestType: 'embedding',
              userId,
              sessionId,
              metadata: { batchSize: batch.length, batchNum, totalBatches },
            });

            // Send all texts in the batch as an array to embedContent
            const result = await this.ai.models.embedContent({
              model: embeddingModel,
              contents: batch, // Send array of texts
              config: {
                outputDimensionality: 768  // Force 768 dimensions for compatibility
              }
            });

            if (!result.embeddings || result.embeddings.length !== batch.length) {
              throw new Error(`Invalid embedding response: expected ${batch.length} embeddings, got ${result.embeddings?.length || 0}`);
            }

            // Extract all embedding vectors
            batchEmbeddings = result.embeddings.map((emb: any) => {
              if (!emb.values) {
                throw new Error('Embedding response missing values');
              }
              return emb.values;
            });

            // Estimate tokens (rough: 1 token â‰ˆ 4 chars, sum all texts)
            const totalChars = batch.reduce((sum, t) => sum + t.length, 0);
            const estimatedTokens = Math.ceil(totalChars / 4);

            await geminiTrackerService.endTracking(trackingId, {
              inputTokens: estimatedTokens,
              outputTokens: 0,
              status: 'success',
            });

            console.log(`[Gemini] âœ… Batch ${batchNum}/${totalBatches}: Successfully generated ${batchEmbeddings.length} embeddings`);
            break; // Success, exit retry loop
          } catch (error) {
            lastError = error;

            if (this.isRetryableError(error) && attempt < this.maxRetries) {
              const delay = this.retryDelay * Math.pow(2, attempt - 1);
              console.warn(`[Gemini] Batch ${batchNum} retry ${attempt}/${this.maxRetries}: ${error}`);
              console.log(`[Gemini] Waiting ${delay}ms before retry...`);
              await this.sleep(delay);
              continue;
            } else {
              console.error(`[Gemini] Batch ${batchNum} failed after ${attempt} attempts`);
              break;
            }
          }
        }

        if (!batchEmbeddings) {
          console.error(`[Gemini] âš ï¸ Batch ${batchNum} failed, falling back to individual requests`);
          // Fallback: Process texts individually if batch fails
          const fallbackResults: number[][] = [];
          for (const text of batch) {
            try {
              const embedding = await this.generateEmbedding(text, sessionId, userId);
              fallbackResults.push(embedding);
            } catch (error) {
              console.error(`[Gemini] Failed to generate embedding for individual text: ${error}`);
              throw error;
            }
          }
          batchEmbeddings = fallbackResults;
        }

        allEmbeddings.push(...batchEmbeddings);

        // Small delay between batches to respect rate limits
        if (i + batchSize < texts.length) {
          await new Promise((resolve) => setTimeout(resolve, 200));
        }
      }

      const duration = ((Date.now() - startTime) / 1000).toFixed(2);
      console.log(`[Gemini] âœ… Completed: ${allEmbeddings.length} embeddings generated in ${duration}s (avg: ${(parseFloat(duration) / allEmbeddings.length * 1000).toFixed(0)}ms per embedding)`);
      return allEmbeddings;
    } catch (error) {
      console.error('[Gemini] Batch embedding generation failed:', error);
      throw error;
    }
  }

  /**
   * Generate answer using RAG (Retrieval-Augmented Generation)
   */
  async generateRAGAnswer(
    query: RAGQuery,
    retrievedChunks: RetrievedChunk[],
    sessionId?: string,
    userId?: string
  ): Promise<RAGResponse> {
    try {
      console.log(`[Gemini] Generating RAG answer for query: "${query.question.substring(0, 50)}..."`);

      // Apply intelligent filtering (Phase 2 optimization)
      const maxChunks = query.topK || 12;
      const filteredChunks = this.filterChunksByRelevance(retrievedChunks, maxChunks, 0.5);

      // Build context from filtered chunks
      const context = filteredChunks
        .map((chunk, idx) => {
          const source = chunk.documentNumber
            ? `${chunk.documentName} (${chunk.documentNumber})`
            : chunk.documentName;

          let location = '';
          if (chunk.metadata.chapterNumber) {
            location += `ChÆ°Æ¡ng ${chunk.metadata.chapterNumber}`;
          }
          if (chunk.metadata.articleNumber) {
            location += location ? `, Äiá»u ${chunk.metadata.articleNumber}` : `Äiá»u ${chunk.metadata.articleNumber}`;
          }

          return `[${idx + 1}] ${source}${location ? ` - ${location}` : ''}:\n${chunk.content}`;
        })
        .join('\n\n---\n\n');

      console.log(`[Gemini] Context built from ${filteredChunks.length} filtered chunks (was ${retrievedChunks.length})`);

      const prompt = this.buildRAGPrompt(query.question, context, query.format || 'prose');

      const modelInfo = await this.getAnswerModel();

      // Generate answer with retry logic
      let lastError: any;
      for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
        try {
          console.log(`[Gemini] RAG answer attempt ${attempt}/${this.maxRetries}`);

          const response = await this.ai.models.generateContent({
            model: modelInfo.name,
            contents: prompt,
          });

          const answer = response.text || '';

          // Get token usage (if available)
          const usageMetadata: any = (response as any).usageMetadata || {};
          const inputTokens = usageMetadata.promptTokenCount || 0;
          const outputTokens = usageMetadata.candidatesTokenCount || 0;
          const totalTokens = usageMetadata.totalTokenCount || inputTokens + outputTokens;

          console.log(`[Gemini] RAG answer generated, tokens: ${totalTokens}`);

          // Parse structured quiz answer if available
          let structuredAnswer: any = null;
          try {
            const jsonMatch = answer.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
              structuredAnswer = JSON.parse(jsonMatch[0]);
              console.log('[Gemini] Parsed structured quiz answer:', structuredAnswer);
            }
          } catch (parseError) {
            console.warn('[Gemini] Could not parse structured answer, using raw text');
          }

          // Calculate confidence based on retrieval scores
          const avgScore = filteredChunks.reduce((sum, c) => sum + c.score, 0) / filteredChunks.length;
          const maxScore = Math.max(...filteredChunks.map(c => c.score));
          const minScore = Math.min(...filteredChunks.map(c => c.score));
          const confidence = Math.round(avgScore * 100);

          console.log(`[Gemini] Confidence calculation:`);
          console.log(`  - Avg Score: ${avgScore.toFixed(4)} (${confidence}%)`);
          console.log(`  - Max Score: ${maxScore.toFixed(4)}`);
          console.log(`  - Min Score: ${minScore.toFixed(4)}`);
          console.log(`  - Chunks used: ${filteredChunks.length}`);

          return {
            answer: structuredAnswer || answer,
            sources: filteredChunks, // Return filtered chunks
            model: modelInfo.name,
            confidence: structuredAnswer?.confidence || confidence,
            tokenUsage: {
              input: inputTokens,
              output: outputTokens,
              total: totalTokens,
            },
            structured: !!structuredAnswer
          };
        } catch (error) {
          lastError = error;

          if (this.isRetryableError(error) && attempt < this.maxRetries) {
            const delay = this.retryDelay * Math.pow(2, attempt - 1);
            console.warn(`[Gemini] RAG answer retry ${attempt}/${this.maxRetries}: ${error}`);
            console.log(`[Gemini] Waiting ${delay}ms before retry...`);
            await this.sleep(delay);
            continue;
          }
        }
      }

      // All retries failed
      throw lastError;
    } catch (error) {
      console.error('[Gemini] RAG answer generation failed:', error);
      throw new Error(`Failed to generate answer: ${error}`);
    }
  }

  /**
   * Generate answer using RAG with streaming (with retry logic)
   */
  async *generateRAGAnswerStream(
    query: RAGQuery,
    retrievedChunks: RetrievedChunk[],
    sessionId?: string,
    userId?: string
  ): AsyncGenerator<{ chunk: string; done: boolean; metadata?: any }> {
    console.log(`[Gemini] Generating streaming RAG answer for query: "${query.question.substring(0, 50)}..."`);

    // Apply intelligent filtering (Phase 2 optimization)
    const maxChunks = query.topK || 12;
    const filteredChunks = this.filterChunksByRelevance(retrievedChunks, maxChunks, 0.5);

    // Build context from filtered chunks
    const context = filteredChunks
      .map((chunk, idx) => {
        const source = chunk.documentNumber
          ? `${chunk.documentName} (${chunk.documentNumber})`
          : chunk.documentName;

        let location = '';
        if (chunk.metadata.chapterNumber) {
          location += `ChÆ°Æ¡ng ${chunk.metadata.chapterNumber}`;
        }
        if (chunk.metadata.articleNumber) {
          location += location ? `, Äiá»u ${chunk.metadata.articleNumber}` : `Äiá»u ${chunk.metadata.articleNumber}`;
        }

        return `[${idx + 1}] ${source}${location ? ` - ${location}` : ''}:\n${chunk.content}`;
      })
      .join('\n\n---\n\n');

    console.log(`[Gemini] Context built from ${filteredChunks.length} filtered chunks (was ${retrievedChunks.length})`);

    const prompt = this.buildRAGPrompt(query.question, context, query.format || 'prose');

    // Retry logic for streaming
    let lastError: any;
    for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
      let trackingId: string | undefined;
      try {
        console.log(`[Gemini] Streaming attempt ${attempt}/${this.maxRetries}`);

        const modelInfo = await this.getAnswerModel();
        console.log(`[Gemini] Streaming with model: ${modelInfo.name}`);

        trackingId = await geminiTrackerService.startTracking({
          endpoint: 'generateContentStream',
          modelName: modelInfo.name,
          modelPriority: modelInfo.priority,
          requestType: 'chat',
          userId,
          sessionId,
          metadata: {
            question: query.question.substring(0, 100),
            chunkCount: filteredChunks.length,
          },
        });

        const streamPromise = this.ai.models.generateContentStream({
          model: modelInfo.name,
          contents: prompt,
        });

        const stream = await streamPromise;

        let fullText = '';
        let tokenCount = 0;

        for await (const chunk of stream) {
          const text = chunk.text || '';
          fullText += text;
          tokenCount += Math.ceil(text.length / 4); // Rough estimate
          yield { chunk: text, done: false };
        }

        // Estimate tokens (rough: prompt + response)
        const estimatedInputTokens = Math.ceil(prompt.length / 4);
        const estimatedOutputTokens = tokenCount;

        await geminiTrackerService.endTracking(trackingId, {
          inputTokens: estimatedInputTokens,
          outputTokens: estimatedOutputTokens,
          status: 'success',
        });

        // Calculate confidence based on retrieval scores
        const avgScore = filteredChunks.reduce((sum, c) => sum + c.score, 0) / filteredChunks.length;
        const confidence = Math.round(avgScore * 100);

        console.log(`[Gemini] Streaming completed, total length: ${fullText.length}`);

        // Parse structured quiz answer if available
        let structuredAnswer: any = null;
        try {
          const jsonMatch = fullText.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
            structuredAnswer = JSON.parse(jsonMatch[0]);
            console.log('[Gemini] Parsed structured quiz answer (streaming):', structuredAnswer);
          }
        } catch (parseError) {
          console.warn('[Gemini] Could not parse structured answer in streaming, using raw text');
        }

        // Final chunk with metadata (use filtered chunks for sources)
        yield {
          chunk: '',
          done: true,
          metadata: {
            model: modelInfo.name,
            confidence: structuredAnswer?.confidence || confidence,
            sources: filteredChunks,
            answer: structuredAnswer || fullText,
            structured: !!structuredAnswer
          }
        };

        return; // Success, exit retry loop
      } catch (error) {
        lastError = error;

        // Try to end tracking with error status if trackingId exists
        if (typeof trackingId !== 'undefined') {
          try {
            await geminiTrackerService.endTracking(trackingId, {
              inputTokens: 0,
              outputTokens: 0,
              status: 'error',
              errorMessage: String(error).substring(0, 500),
              retryCount: attempt,
            });
          } catch (trackingError) {
            console.warn('[Gemini] Failed to record error tracking:', trackingError);
          }
        }

        if (this.isRetryableError(error) && attempt < this.maxRetries) {
          const delay = this.retryDelay * Math.pow(2, attempt - 1);
          console.warn(`[Gemini] Streaming retry ${attempt}/${this.maxRetries}: ${error}`);
          console.log(`[Gemini] Waiting ${delay}ms before retry...`);
          await this.sleep(delay);
          continue;
        } else {
          // Non-retryable or max retries reached
          console.error(`[Gemini] Streaming failed after ${attempt} attempts:`, error);
          break;
        }
      }
    }

    // All retries failed
    console.error('[Gemini] RAG streaming failed:', lastError);
    throw new Error(`Failed to stream answer: ${lastError}`);
  }

  /**
   * Filter chunks by relevance and remove duplicates (Phase 2 optimization)
   */
  private filterChunksByRelevance(
    chunks: RetrievedChunk[],
    maxChunks: number,
    minScore: number = 0.6
  ): RetrievedChunk[] {
    console.log(`[Gemini] Filtering ${chunks.length} chunks, maxChunks: ${maxChunks}, minScore: ${minScore}`);

    // Step 1: Filter by minimum score
    let filtered = chunks.filter(chunk => chunk.score >= minScore);
    console.log(`[Gemini] After score filter: ${filtered.length} chunks`);

    // Step 2: Group by document and prioritize higher scores within same document
    const byDocument = new Map<string, RetrievedChunk[]>();
    filtered.forEach(chunk => {
      const docKey = chunk.documentNumber || chunk.documentName;
      if (!byDocument.has(docKey)) {
        byDocument.set(docKey, []);
      }
      byDocument.get(docKey)!.push(chunk);
    });

    // Step 3: Sort chunks within each document by score and take top ones
    const maxChunksPerDoc = Math.min(3, Math.ceil(maxChunks / byDocument.size));
    const balanced: RetrievedChunk[] = [];

    for (const [docName, docChunks] of byDocument) {
      const sortedChunks = docChunks
        .sort((a, b) => b.score - a.score)
        .slice(0, maxChunksPerDoc);
      balanced.push(...sortedChunks);
      console.log(`[Gemini] Document "${docName}": ${sortedChunks.length}/${docChunks.length} chunks selected`);
    }

    // Step 4: Remove content duplicates using simple similarity
    const deduplicated = this.removeDuplicateContent(balanced);

    // Step 5: Final sort by score and limit to maxChunks
    const final = deduplicated
      .sort((a, b) => b.score - a.score)
      .slice(0, maxChunks);

    console.log(`[Gemini] Final selection: ${final.length} chunks from ${byDocument.size} documents`);
    return final;
  }

  /**
   * Remove chunks with similar content
   */
  private removeDuplicateContent(chunks: RetrievedChunk[]): RetrievedChunk[] {
    const result: RetrievedChunk[] = [];

    for (const chunk of chunks) {
      let isDuplicate = false;

      for (const existing of result) {
        // Simple content similarity check
        const similarity = this.calculateContentSimilarity(chunk.content, existing.content);
        if (similarity > 0.8) { // 80% similar
          isDuplicate = true;
          // Keep the one with higher score
          if (chunk.score > existing.score) {
            const index = result.indexOf(existing);
            result[index] = chunk;
          }
          break;
        }
      }

      if (!isDuplicate) {
        result.push(chunk);
      }
    }

    console.log(`[Gemini] Deduplication: ${chunks.length} â†’ ${result.length} chunks`);
    return result;
  }

  /**
   * Calculate simple content similarity between two texts
   */
  private calculateContentSimilarity(text1: string, text2: string): number {
    // Normalize texts
    const normalize = (text: string) => text.toLowerCase().replace(/\s+/g, ' ').trim();
    const norm1 = normalize(text1);
    const norm2 = normalize(text2);

    if (norm1 === norm2) return 1.0;

    // Simple word-based similarity
    const words1 = new Set(norm1.split(' '));
    const words2 = new Set(norm2.split(' '));

    const intersection = new Set([...words1].filter(w => words2.has(w)));
    const union = new Set([...words1, ...words2]);

    return intersection.size / union.size;
  }

  /**
   * Build RAG prompt (optimized version)
   */
  private buildRAGPrompt(question: string, context: string, format: 'json' | 'prose' = 'prose'): string {
    // Check if it's a multiple choice question
    const isMultipleChoiceQuestion = this.isMultipleChoiceQuestion(question);

    // Only use JSON format if explicitly requested AND it's a multiple choice question
    if (format === 'json' && isMultipleChoiceQuestion) {
      // Multiple choice question - return specific answer format
      const hasExtractedOptions = question.includes('CÃ¡c Ä‘Ã¡p Ã¡n:');

      if (hasExtractedOptions) {
        // Image-based question with extracted options
        return `
Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn nghiá»‡p vá»¥ ngÃ¢n hÃ ng. Dá»±a trÃªn cÃ¡c vÄƒn báº£n quy Ä‘á»‹nh Ä‘Æ°á»£c cung cáº¥p, hÃ£y phÃ¢n tÃ­ch vÃ  chá»n Ä‘Ã¡p Ã¡n Ä‘Ãºng.

NGUYÃŠN Táº®C:
1. PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  cÃ¡c Ä‘Ã¡p Ã¡n Ä‘Æ°á»£c cung cáº¥p tá»« hÃ¬nh áº£nh
2. Dá»±a trÃªn tÃ i liá»‡u Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Ä‘Ã¡p Ã¡n CHÃNH XÃC nháº¥t
3. Tráº£ vá» chá»‰ chá»¯ cÃ¡i Ä‘Ã¡p Ã¡n Ä‘Ãºng (A, B, C, hoáº·c D)
4. ÄÆ°a ra nguá»“n vÄƒn báº£n cá»¥ thá»ƒ (Ä‘iá»u, khoáº£n)
5. Tráº£ vá» dÆ°á»›i dáº¡ng JSON vá»›i format:

{
  "correctAnswer": "A|B|C|D",
  "explanation": "Giáº£i thÃ­ch ngáº¯n gá»n (1-2 cÃ¢u)",
  "source": "Äiá»u X, Khoáº£n Y - TÃªn vÄƒn báº£n", 
  "confidence": 85
}

NGá»® Cáº¢NH:
${context}

CÃ‚U Há»I VÃ€ CÃC ÄÃP ÃN: ${question}

Tráº£ vá» JSON theo format trÃªn:
`;
      } else {
        // Generate multiple choice options
        return `
Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn nghiá»‡p vá»¥ ngÃ¢n hÃ ng. Dá»±a trÃªn cÃ¡c vÄƒn báº£n quy Ä‘á»‹nh Ä‘Æ°á»£c cung cáº¥p, hÃ£y táº¡o cÃ¢u tráº£ lá»i dáº¡ng tráº¯c nghiá»‡m cho cÃ¢u há»i.

NGUYÃŠN Táº®C:
1. PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  tÃ¬m Ä‘Ã¡p Ã¡n CHÃNH XÃC tá»« tÃ i liá»‡u
2. Táº¡o 4 Ä‘Ã¡p Ã¡n A, B, C, D (trong Ä‘Ã³ cÃ³ 1 Ä‘Ã¡p Ã¡n Ä‘Ãºng vÃ  3 Ä‘Ã¡p Ã¡n sai há»£p lÃ½)
3. ÄÆ°a ra giáº£i thÃ­ch ngáº¯n gá»n vá»›i nguá»“n vÄƒn báº£n (Ä‘iá»u, khoáº£n cá»¥ thá»ƒ)
4. Tráº£ vá» dÆ°á»›i dáº¡ng JSON vá»›i format:

{
  "correctAnswer": "A|B|C|D",
  "options": {
    "A": "ÄÃ¡p Ã¡n A",
    "B": "ÄÃ¡p Ã¡n B", 
    "C": "ÄÃ¡p Ã¡n C",
    "D": "ÄÃ¡p Ã¡n D"
  },
  "explanation": "Giáº£i thÃ­ch ngáº¯n gá»n (1-2 cÃ¢u)",
  "source": "Äiá»u X, Khoáº£n Y - TÃªn vÄƒn báº£n",
  "confidence": 85
}

NGá»® Cáº¢NH:
${context}

CÃ‚U Há»I: ${question}

Tráº£ vá» JSON theo format trÃªn:
`;
      }
    } else {
      // Regular question OR prose format requested - return natural text response
      return `
Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» phÃ¡p luáº­t Viá»‡t Nam. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng dá»±a trÃªn cÃ¡c vÄƒn báº£n phÃ¡p luáº­t Ä‘Æ°á»£c cung cáº¥p.

NGUYÃŠN Táº®C TRáº¢ Lá»œI:
1. Tráº£ lá»i CHÃNH XÃC dá»±a trÃªn ná»™i dung vÄƒn báº£n Ä‘Æ°á»£c cung cáº¥p
2. TrÃ­ch dáº«n cá»¥ thá»ƒ Ä‘iá»u, khoáº£n liÃªn quan TRONG CÃ‚U báº±ng cÃ¡ch thÃªm kÃ½ hiá»‡u [ğŸ”—1], [ğŸ”—2], [ğŸ”—3] ngay sau cÃ¢u hoáº·c Ä‘oáº¡n cÃ³ liÃªn quan
3. Náº¿u cÃ¢u há»i yÃªu cáº§u Ä‘áº¿m, tÃ­nh tá»•ng, tÃ³m táº¯t: hÃ£y phÃ¢n tÃ­ch TOÃ€N Bá»˜ ná»™i dung Ä‘Æ°á»£c cung cáº¥p vÃ  Ä‘Æ°a ra káº¿t quáº£ chÃ­nh xÃ¡c
4. Khi liá»‡t kÃª, hÃ£y sáº¯p xáº¿p theo thá»© tá»± logic (theo sá»‘ Ä‘iá»u, chÆ°Æ¡ng, hoáº·c thá»© tá»± xuáº¥t hiá»‡n)
5. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n, dá»… hiá»ƒu, KHÃ”NG sá»­ dá»¥ng markdown (*, #, **, _)
6. Viáº¿t cÃ¢u tráº£ lá»i tá»± nhiÃªn nhÆ° vÄƒn xuÃ´i thÃ´ng thÆ°á»ng
7. Sá»‘ [ğŸ”—n] tÆ°Æ¡ng á»©ng vá»›i nguá»“n thá»© n trong danh sÃ¡ch ngá»¯ cáº£nh bÃªn dÆ°á»›i
8. Náº¿u nhiá»u nguá»“n há»— trá»£ cÃ¹ng má»™t Ã½, cÃ³ thá»ƒ dÃ¹ng [ğŸ”—1][ğŸ”—2]

VÃ Dá»¤ FORMAT:
- CÃ¢u há»i thÃ´ng thÆ°á»ng: "Theo quy Ä‘á»‹nh, ngÆ°á»i lao Ä‘á»™ng cÃ³ quyá»n nghá»‰ phÃ©p nÄƒm 12 ngÃ y lÃ m viá»‡c [ğŸ”—1]. Äá»‘i vá»›i nhá»¯ng ngÆ°á»i lÃ m viá»‡c trong Ä‘iá»u kiá»‡n Ä‘áº·c biá»‡t, thá»i gian nghá»‰ phÃ©p cÃ³ thá»ƒ tÄƒng lÃªn [ğŸ”—2][ğŸ”—3]."
- CÃ¢u há»i Ä‘áº¿m/tá»•ng há»£p: "VÄƒn báº£n cÃ³ tá»•ng cá»™ng 15 Ä‘iá»u khoáº£n vá» váº¥n Ä‘á» nÃ y, bao gá»“m: Äiá»u 5 vá» quyá»n lá»£i ngÆ°á»i lao Ä‘á»™ng [ğŸ”—1], Äiá»u 7 vá» nghÄ©a vá»¥ cá»§a ngÆ°á»i sá»­ dá»¥ng lao Ä‘á»™ng [ğŸ”—3], Äiá»u 12 vá» cháº¿ Ä‘á»™ báº£o hiá»ƒm [ğŸ”—5]..."

NGá»® Cáº¢NH Tá»ª CÃC VÄ‚N Báº¢N:
${context}

CÃ‚U Há»I: ${question}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ngá»¯ cáº£nh trÃªn, nhá»› thÃªm trÃ­ch dáº«n [ğŸ”—n] sau má»—i cÃ¢u/Ä‘oáº¡n cÃ³ liÃªn quan.
`;
    }
  }

  /**
   * Check if question is a multiple choice question
   */
  private isMultipleChoiceQuestion(question: string): boolean {
    // Check for explicit multiple choice indicators
    const multipleChoiceIndicators = [
      'CÃ¡c Ä‘Ã¡p Ã¡n:',
      'A)', 'B)', 'C)', 'D)',
      'A.', 'B.', 'C.', 'D.',
      'a)', 'b)', 'c)', 'd)',
      'a.', 'b.', 'c.', 'd.',
      'chá»n Ä‘Ã¡p Ã¡n',
      'Ä‘Ã¡p Ã¡n nÃ o',
      'Ä‘Ã¡p Ã¡n Ä‘Ãºng',
      'lá»±a chá»n nÃ o',
      'phÆ°Æ¡ng Ã¡n nÃ o',
      'trÆ°á»ng há»£p nÃ o',
      'cÃ¢u nÃ o Ä‘Ãºng',
      'Ã½ kiáº¿n nÃ o',
      'tÃ¬nh huá»‘ng nÃ o'
    ];

    const lowerQuestion = question.toLowerCase();

    // Check if question contains explicit multiple choice patterns
    for (const indicator of multipleChoiceIndicators) {
      if (lowerQuestion.includes(indicator.toLowerCase())) {
        return true;
      }
    }

    // Check for option patterns like "A) option text B) option text"
    const optionPatterns = [
      /[A-D]\)[^\n]*[A-D]\)/i,  // A) text B) pattern
      /[A-D]\.[^\n]*[A-D]\./i,  // A. text B. pattern
      /[a-d]\)[^\n]*[a-d]\)/i,  // a) text b) pattern
      /[a-d]\.[^\n]*[a-d]\./i   // a. text b. pattern
    ];

    for (const pattern of optionPatterns) {
      if (pattern.test(question)) {
        return true;
      }
    }

    return false;
  }

  /**
   * Generate answer using RAG (Retrieval-Augmented Generation)
   * @deprecated Use generateRAGAnswerStream for better UX
   */
  async generateRAGAnswerLegacy(
    query: RAGQuery,
    retrievedChunks: RetrievedChunk[]
  ): Promise<RAGResponse> {
    try {
      console.log(`[Gemini] Generating RAG answer for query: "${query.question.substring(0, 50)}..."`);

      // Build context from retrieved chunks
      const context = retrievedChunks
        .map((chunk, idx) => {
          const source = chunk.documentNumber
            ? `${chunk.documentName} (${chunk.documentNumber})`
            : chunk.documentName;

          let location = '';
          if (chunk.metadata.chapterNumber) {
            location += `ChÆ°Æ¡ng ${chunk.metadata.chapterNumber}`;
          }
          if (chunk.metadata.articleNumber) {
            location += location ? `, Äiá»u ${chunk.metadata.articleNumber}` : `Äiá»u ${chunk.metadata.articleNumber}`;
          }

          return `[${idx + 1}] ${source}${location ? ` - ${location}` : ''}:\n${chunk.content}`;
        })
        .join('\n\n---\n\n');

      const prompt = `
Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» phÃ¡p luáº­t Viá»‡t Nam. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng dá»±a trÃªn cÃ¡c vÄƒn báº£n phÃ¡p luáº­t Ä‘Æ°á»£c cung cáº¥p.

NGUYÃŠN Táº®C TRáº¢ Lá»œI:
1. Tráº£ lá»i CHÃNH XÃC dá»±a trÃªn ná»™i dung vÄƒn báº£n Ä‘Æ°á»£c cung cáº¥p
2. TrÃ­ch dáº«n cá»¥ thá»ƒ Ä‘iá»u, khoáº£n liÃªn quan TRONG CÃ‚U báº±ng cÃ¡ch thÃªm kÃ½ hiá»‡u [ğŸ”—1], [ğŸ”—2], [ğŸ”—3] ngay sau cÃ¢u hoáº·c Ä‘oáº¡n cÃ³ liÃªn quan
3. Náº¿u cÃ¢u há»i yÃªu cáº§u Ä‘áº¿m, tÃ­nh tá»•ng, tÃ³m táº¯t: hÃ£y phÃ¢n tÃ­ch TOÃ€N Bá»˜ ná»™i dung Ä‘Æ°á»£c cung cáº¥p vÃ  Ä‘Æ°a ra káº¿t quáº£ chÃ­nh xÃ¡c
4. Khi liá»‡t kÃª, hÃ£y sáº¯p xáº¿p theo thá»© tá»± logic (theo sá»‘ Ä‘iá»u, chÆ°Æ¡ng, hoáº·c thá»© tá»± xuáº¥t hiá»‡n)
5. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n, dá»… hiá»ƒu, KHÃ”NG sá»­ dá»¥ng markdown (*, #, **, _)
6. Viáº¿t cÃ¢u tráº£ lá»i tá»± nhiÃªn nhÆ° vÄƒn xuÃ´i thÃ´ng thÆ°á»ng
7. Sá»‘ [ğŸ”—n] tÆ°Æ¡ng á»©ng vá»›i nguá»“n thá»© n trong danh sÃ¡ch ngá»¯ cáº£nh bÃªn dÆ°á»›i
8. Náº¿u nhiá»u nguá»“n há»— trá»£ cÃ¹ng má»™t Ã½, cÃ³ thá»ƒ dÃ¹ng [ğŸ”—1][ğŸ”—2]

VÃ Dá»¤ FORMAT:
- CÃ¢u há»i thÃ´ng thÆ°á»ng: "Theo quy Ä‘á»‹nh, ngÆ°á»i lao Ä‘á»™ng cÃ³ quyá»n nghá»‰ phÃ©p nÄƒm 12 ngÃ y lÃ m viá»‡c [ğŸ”—1]. Äá»‘i vá»›i nhá»¯ng ngÆ°á»i lÃ m viá»‡c trong Ä‘iá»u kiá»‡n Ä‘áº·c biá»‡t, thá»i gian nghá»‰ phÃ©p cÃ³ thá»ƒ tÄƒng lÃªn [ğŸ”—2][ğŸ”—3]."
- CÃ¢u há»i Ä‘áº¿m/tá»•ng há»£p: "VÄƒn báº£n cÃ³ tá»•ng cá»™ng 15 Ä‘iá»u khoáº£n vá» váº¥n Ä‘á» nÃ y, bao gá»“m: Äiá»u 5 vá» quyá»n lá»£i ngÆ°á»i lao Ä‘á»™ng [ğŸ”—1], Äiá»u 7 vá» nghÄ©a vá»¥ cá»§a ngÆ°á»i sá»­ dá»¥ng lao Ä‘á»™ng [ğŸ”—3], Äiá»u 12 vá» cháº¿ Ä‘á»™ báº£o hiá»ƒm [ğŸ”—5]..."

NGá»® Cáº¢NH Tá»ª CÃC VÄ‚N Báº¢N:
${context}

CÃ‚U Há»I: ${query.question}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ngá»¯ cáº£nh trÃªn, nhá»› thÃªm trÃ­ch dáº«n [ğŸ”—n] sau má»—i cÃ¢u/Ä‘oáº¡n cÃ³ liÃªn quan.
`;

      const modelInfo = await this.getAnswerModel();

      // Generate answer with retry logic
      let lastError: any;
      for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
        try {
          console.log(`[Gemini] RAG answer attempt ${attempt}/${this.maxRetries}`);

          const response = await this.ai.models.generateContent({
            model: modelInfo.name,
            contents: prompt,
          });

          const answer = response.text || '';

          // Get token usage (if available)
          const usageMetadata: any = (response as any).usageMetadata || {};
          const inputTokens = usageMetadata.promptTokenCount || 0;
          const outputTokens = usageMetadata.candidatesTokenCount || 0;
          const totalTokens = usageMetadata.totalTokenCount || inputTokens + outputTokens;

          console.log(`[Gemini] RAG answer generated, tokens: ${totalTokens}`);

          // Calculate confidence based on retrieval scores
          const avgScore = retrievedChunks.reduce((sum, c) => sum + c.score, 0) / retrievedChunks.length;
          const confidence = Math.round(avgScore * 100);

          return {
            answer,
            sources: retrievedChunks,
            model: modelInfo.name,
            confidence,
            tokenUsage: {
              input: inputTokens,
              output: outputTokens,
              total: totalTokens,
            },
          };
        } catch (error) {
          lastError = error;

          if (this.isRetryableError(error) && attempt < this.maxRetries) {
            const delay = this.retryDelay * Math.pow(2, attempt - 1);
            console.warn(`[Gemini] RAG answer retry ${attempt}/${this.maxRetries}: ${error}`);
            console.log(`[Gemini] Waiting ${delay}ms before retry...`);
            await this.sleep(delay);
            continue;
          }
        }
      }

      // All retries failed
      throw lastError;
    } catch (error) {
      console.error('[Gemini] RAG answer generation failed:', error);
      throw new Error(`Failed to generate answer: ${error}`);
    }
  }

  /**
   * Convert DocumentContent to Markdown
   */
  convertToMarkdown(content: DocumentContent): string {
    let markdown = '';

    // Overview
    const { overview } = content;
    markdown += `# ${overview.documentName}\n\n`;

    if (overview.documentNumber) {
      markdown += `**Sá»‘ vÄƒn báº£n:** ${overview.documentNumber}\n\n`;
    }
    if (overview.documentType) {
      markdown += `**Loáº¡i vÄƒn báº£n:** ${overview.documentType}\n\n`;
    }
    if (overview.issuingAgency) {
      markdown += `**CÆ¡ quan ban hÃ nh:** ${overview.issuingAgency}\n\n`;
    }
    if (overview.signer) {
      markdown += `**NgÆ°á»i kÃ½:** ${overview.signer.name}`;
      if (overview.signer.title) {
        markdown += ` - ${overview.signer.title}`;
      }
      markdown += '\n\n';
    }
    if (overview.signedDate) {
      markdown += `**NgÃ y kÃ½:** ${overview.signedDate}\n\n`;
    }

    markdown += '---\n\n';

    // Basis
    if (content.basis && content.basis.length > 0) {
      markdown += '## CÄƒn cá»©\n\n';
      content.basis.forEach((basis) => {
        markdown += `- ${basis.type}`;
        if (basis.number) markdown += ` sá»‘ ${basis.number}`;
        markdown += ` ${basis.name}`;
        if (basis.date) markdown += ` ngÃ y ${basis.date}`;
        markdown += '\n';
      });
      markdown += '\n';
    }

    // Chapters or Articles
    if (content.chapters && content.chapters.length > 0) {
      // Document has chapters
      content.chapters.forEach((chapter) => {
        markdown += `## ChÆ°Æ¡ng ${chapter.number}: ${chapter.title}\n\n`;

        chapter.articles.forEach((article) => {
          markdown += `### Äiá»u ${article.number}`;
          if (article.title) markdown += `. ${article.title}`;
          markdown += '\n\n';

          if (article.content) {
            markdown += `${article.content}\n\n`;
          }

          if (article.sections && article.sections.length > 0) {
            article.sections.forEach((section) => {
              if (section.number) {
                markdown += `${section.number}. ${section.content}\n\n`;
              } else {
                markdown += `${section.content}\n\n`;
              }

              if (section.subsections && section.subsections.length > 0) {
                section.subsections.forEach((sub) => {
                  markdown += `   ${sub}\n\n`;
                });
              }
            });
          }
        });
      });
    } else if (content.articles && content.articles.length > 0) {
      // Document has no chapters, only articles
      content.articles.forEach((article) => {
        markdown += `## Äiá»u ${article.number}`;
        if (article.title) markdown += `. ${article.title}`;
        markdown += '\n\n';

        if (article.content) {
          markdown += `${article.content}\n\n`;
        }

        if (article.sections && article.sections.length > 0) {
          article.sections.forEach((section) => {
            if (section.number) {
              markdown += `${section.number}. ${section.content}\n\n`;
            } else {
              markdown += `${section.content}\n\n`;
            }

            if (section.subsections && section.subsections.length > 0) {
              section.subsections.forEach((sub) => {
                markdown += `   ${sub}\n\n`;
              });
            }
          });
        }
      });
    }

    // Appendices
    if (content.appendices && content.appendices.length > 0) {
      markdown += '---\n\n';
      content.appendices.forEach((appendix) => {
        markdown += `## Phá»¥ lá»¥c ${appendix.number || ''}: ${appendix.title}\n\n`;
        markdown += `${appendix.content}\n\n`;
      });
    }

    return markdown;
  }
}

// Export singleton instances
// Default instance using GEMINI_API_KEY for chat queries
export const geminiRAGService = new GeminiRAGService();

// Import instance using GEMINI_API_KEY_IMPORT for file import/embedding
export const geminiRAGServiceImport = new GeminiRAGService(process.env.GEMINI_API_KEY_IMPORT);
